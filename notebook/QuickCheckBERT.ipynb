{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iqCpXNaZSrR",
        "outputId": "4c996fad-fc3a-4646-dc7e-c936303114d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (1.19.5)\n",
            "Requirement already satisfied: pandas in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from pandas) (2021.3)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (0.24.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from scikit-learn) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from scikit-learn) (1.5.4)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from scikit-learn) (1.19.5)\n",
            "Requirement already satisfied: tensorflow==1.15 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (0.37.0)\n",
            "Requirement already satisfied: gast==0.2.2 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (3.19.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (1.43.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: h5py in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (58.0.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.2)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.8.3)\n",
            "Requirement already satisfied: dataclasses in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from werkzeug>=0.11.15->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (0.8)\n",
            "Requirement already satisfied: cached-property in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\klemo\\appdata\\roaming\\python\\python36\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.6.0)\n",
            "Requirement already satisfied: bert-tensorflow==1.0.1 in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: six in c:\\users\\klemo\\anaconda3\\envs\\quickcheck\\lib\\site-packages (from bert-tensorflow==1.0.1) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow==1.15\n",
        "!pip install bert-tensorflow==1.0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JNyBm2ZSZSrV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dto1TBUzZSrY",
        "outputId": "9f4949be-e90f-4778-96f7-26a00719e211"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.15.0\n",
            "3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print (sys.version)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-_wd4n4yaIuL"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "import logging, sys\n",
        "\n",
        "logging.disable(sys.maxsize)\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIfmxHB8ZSrZ",
        "outputId": "65c4f38e-88ff-4dbd-fe5a-c805385f4b02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 16996312281412840453\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gEhwu7dBZSrb"
      },
      "outputs": [],
      "source": [
        "import bert\n",
        "\n",
        "#Load submodules\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YOU8p-iZSre"
      },
      "source": [
        "Import Datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "1ETg5z02ah1X"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# train_upload = files.upload()\n",
        "# test_upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qn_bhfyRZSrg"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "path = '../data/' \n",
        "\n",
        "train = pd.read_csv(path + 'dreaddit-train.csv', encoding = \"ISO-8859-1\")\n",
        "test = pd.read_csv(path + 'dreaddit-test.csv', encoding = \"ISO-8859-1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "Jvfl7NKgbfpc",
        "outputId": "95451108-9842-4224-ad1a-290185d0eba6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>subreddit</th>\n",
              "      <th>post_id</th>\n",
              "      <th>sentence_range</th>\n",
              "      <th>text</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>confidence</th>\n",
              "      <th>social_timestamp</th>\n",
              "      <th>social_karma</th>\n",
              "      <th>syntax_ari</th>\n",
              "      <th>...</th>\n",
              "      <th>lex_dal_min_pleasantness</th>\n",
              "      <th>lex_dal_min_activation</th>\n",
              "      <th>lex_dal_min_imagery</th>\n",
              "      <th>lex_dal_avg_activation</th>\n",
              "      <th>lex_dal_avg_imagery</th>\n",
              "      <th>lex_dal_avg_pleasantness</th>\n",
              "      <th>social_upvote_ratio</th>\n",
              "      <th>social_num_comments</th>\n",
              "      <th>syntax_fk_grade</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>8601tu</td>\n",
              "      <td>(15, 20)</td>\n",
              "      <td>He said he had not felt that way before, sugge...</td>\n",
              "      <td>33181</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1521614353</td>\n",
              "      <td>5</td>\n",
              "      <td>1.806818</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.77000</td>\n",
              "      <td>1.52211</td>\n",
              "      <td>1.89556</td>\n",
              "      <td>0.86</td>\n",
              "      <td>1</td>\n",
              "      <td>3.253573</td>\n",
              "      <td>-0.002742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>assistance</td>\n",
              "      <td>8lbrx9</td>\n",
              "      <td>(0, 5)</td>\n",
              "      <td>Hey there r/assistance, Not sure if this is th...</td>\n",
              "      <td>2606</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1527009817</td>\n",
              "      <td>4</td>\n",
              "      <td>9.429737</td>\n",
              "      <td>...</td>\n",
              "      <td>1.125</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.69586</td>\n",
              "      <td>1.62045</td>\n",
              "      <td>1.88919</td>\n",
              "      <td>0.65</td>\n",
              "      <td>2</td>\n",
              "      <td>8.828316</td>\n",
              "      <td>0.292857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ptsd</td>\n",
              "      <td>9ch1zh</td>\n",
              "      <td>(15, 20)</td>\n",
              "      <td>My mom then hit me with the newspaper and it s...</td>\n",
              "      <td>38816</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1535935605</td>\n",
              "      <td>2</td>\n",
              "      <td>7.769821</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.1429</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.83088</td>\n",
              "      <td>1.58108</td>\n",
              "      <td>1.85828</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0</td>\n",
              "      <td>7.841667</td>\n",
              "      <td>0.011894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>relationships</td>\n",
              "      <td>7rorpp</td>\n",
              "      <td>[5, 10]</td>\n",
              "      <td>until i met my new boyfriend, he is amazing, h...</td>\n",
              "      <td>239</td>\n",
              "      <td>1</td>\n",
              "      <td>0.6</td>\n",
              "      <td>1516429555</td>\n",
              "      <td>0</td>\n",
              "      <td>2.667798</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.75356</td>\n",
              "      <td>1.52114</td>\n",
              "      <td>1.98848</td>\n",
              "      <td>0.50</td>\n",
              "      <td>5</td>\n",
              "      <td>4.104027</td>\n",
              "      <td>0.141671</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>survivorsofabuse</td>\n",
              "      <td>9p2gbc</td>\n",
              "      <td>[0, 5]</td>\n",
              "      <td>October is Domestic Violence Awareness Month a...</td>\n",
              "      <td>1421</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8</td>\n",
              "      <td>1539809005</td>\n",
              "      <td>24</td>\n",
              "      <td>7.554238</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000</td>\n",
              "      <td>1.1250</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.77644</td>\n",
              "      <td>1.64872</td>\n",
              "      <td>1.81456</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1</td>\n",
              "      <td>7.910952</td>\n",
              "      <td>-0.204167</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 116 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          subreddit post_id sentence_range  \\\n",
              "0              ptsd  8601tu       (15, 20)   \n",
              "1        assistance  8lbrx9         (0, 5)   \n",
              "2              ptsd  9ch1zh       (15, 20)   \n",
              "3     relationships  7rorpp        [5, 10]   \n",
              "4  survivorsofabuse  9p2gbc         [0, 5]   \n",
              "\n",
              "                                                text     id  label  \\\n",
              "0  He said he had not felt that way before, sugge...  33181      1   \n",
              "1  Hey there r/assistance, Not sure if this is th...   2606      0   \n",
              "2  My mom then hit me with the newspaper and it s...  38816      1   \n",
              "3  until i met my new boyfriend, he is amazing, h...    239      1   \n",
              "4  October is Domestic Violence Awareness Month a...   1421      1   \n",
              "\n",
              "   confidence  social_timestamp  social_karma  syntax_ari  ...  \\\n",
              "0         0.8        1521614353             5    1.806818  ...   \n",
              "1         1.0        1527009817             4    9.429737  ...   \n",
              "2         0.8        1535935605             2    7.769821  ...   \n",
              "3         0.6        1516429555             0    2.667798  ...   \n",
              "4         0.8        1539809005            24    7.554238  ...   \n",
              "\n",
              "   lex_dal_min_pleasantness  lex_dal_min_activation  lex_dal_min_imagery  \\\n",
              "0                     1.000                  1.1250                  1.0   \n",
              "1                     1.125                  1.0000                  1.0   \n",
              "2                     1.000                  1.1429                  1.0   \n",
              "3                     1.000                  1.1250                  1.0   \n",
              "4                     1.000                  1.1250                  1.0   \n",
              "\n",
              "   lex_dal_avg_activation  lex_dal_avg_imagery  lex_dal_avg_pleasantness  \\\n",
              "0                 1.77000              1.52211                   1.89556   \n",
              "1                 1.69586              1.62045                   1.88919   \n",
              "2                 1.83088              1.58108                   1.85828   \n",
              "3                 1.75356              1.52114                   1.98848   \n",
              "4                 1.77644              1.64872                   1.81456   \n",
              "\n",
              "   social_upvote_ratio  social_num_comments  syntax_fk_grade  sentiment  \n",
              "0                 0.86                    1         3.253573  -0.002742  \n",
              "1                 0.65                    2         8.828316   0.292857  \n",
              "2                 0.67                    0         7.841667   0.011894  \n",
              "3                 0.50                    5         4.104027   0.141671  \n",
              "4                 1.00                    1         7.910952  -0.204167  \n",
              "\n",
              "[5 rows x 116 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QsSI6--ZZSri"
      },
      "outputs": [],
      "source": [
        "DATA_COLUMN = 'text'\n",
        "LABEL_COLUMN = 'label'\n",
        "# label_list contains list of labels (i.e stress, non-stress)\n",
        "label_list = [0, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sc_G0B7oZSrj"
      },
      "outputs": [],
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "oYPU0qiKZSrl"
      },
      "outputs": [],
      "source": [
        "# Load a vocabulary file and lowercasing information directly from the BERT tf hub module\n",
        "\n",
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "    with tf.Graph().as_default():\n",
        "        bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "        tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "        with tf.Session() as sess:\n",
        "            vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                                tokenization_info[\"do_lower_case\"]])\n",
        "\n",
        "    return bert.tokenization.FullTokenizer(vocab_file=vocab_file, \n",
        "                                    do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "o9gWxqD8ZSrn"
      },
      "outputs": [],
      "source": [
        "# Set the maximum sequence length. \n",
        "def get_max_len(text):\n",
        "    max_len = 0\n",
        "    for i in range(len(train)):\n",
        "        if len(text.iloc[i]) > max_len:\n",
        "            max_len = len(text.iloc[i])\n",
        "    return max_len\n",
        "\n",
        "temp = train.text.str.split(' ')\n",
        "max_len = get_max_len(temp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-o3auRoYZSrp"
      },
      "outputs": [],
      "source": [
        "MAX_SEQ_LENGTH = max_len\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, \n",
        "                                                                  label_list, \n",
        "                                                                  MAX_SEQ_LENGTH, \n",
        "                                                                  tokenizer)\n",
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, \n",
        "                                                                 label_list, \n",
        "                                                                 MAX_SEQ_LENGTH, \n",
        "                                                                 tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgWGn5zIbwAl"
      },
      "source": [
        "Classification Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Zv4m13YpbxZL"
      },
      "outputs": [],
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "    \"\"\"Creates a classification model.\"\"\"\n",
        "\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB, trainable=True)\n",
        "    bert_inputs = dict(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids)\n",
        "    bert_outputs = bert_module(inputs=bert_inputs, signature=\"tokens\", as_dict=True)\n",
        "\n",
        "    # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "    # Use \"sequence_outputs\" for token-level output.\n",
        "    output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "    hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "    # Create our own layer to tune for politeness data.\n",
        "    output_weights = tf.get_variable(\n",
        "        \"output_weights\", [num_labels, hidden_size],\n",
        "        initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "    output_bias = tf.get_variable(\"output_bias\", \n",
        "                                  [num_labels], \n",
        "                                  initializer=tf.zeros_initializer())\n",
        "\n",
        "    with tf.variable_scope(\"loss\"):\n",
        "\n",
        "        # Dropout helps prevent overfitting\n",
        "        output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "        logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "        logits = tf.nn.bias_add(logits, output_bias)\n",
        "        log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "        # Convert labels into one-hot encoding\n",
        "        one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "        # unshaped_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "        # predicted_labels = tf.reshape(unshaped_labels, [])\n",
        "        predicted_labels = tf.argmax(log_probs, axis=-1, output_type=tf.int32)\n",
        "        # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "        if is_predicting:\n",
        "            return (predicted_labels, log_probs)\n",
        "\n",
        "        # If we're train/eval, compute loss between predicted and actual label\n",
        "        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "        loss = tf.reduce_mean(per_example_loss)\n",
        "        return (loss, predicted_labels, log_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "w-2PfxDib0ut"
      },
      "outputs": [],
      "source": [
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps, num_warmup_steps):\n",
        "    \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "    def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "        \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "        input_ids = features[\"input_ids\"]\n",
        "        input_mask = features[\"input_mask\"]\n",
        "        segment_ids = features[\"segment_ids\"]\n",
        "        label_ids = features[\"label_ids\"]\n",
        "\n",
        "        is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "        # TRAIN and EVAL\n",
        "        if not is_predicting:\n",
        "            (loss, predicted_labels, log_probs) = create_model(is_predicting, \n",
        "                                                               input_ids, \n",
        "                                                               input_mask, \n",
        "                                                               segment_ids, \n",
        "                                                               label_ids, \n",
        "                                                               num_labels)\n",
        "\n",
        "            train_op = bert.optimization.create_optimizer(loss, \n",
        "                                                          learning_rate, \n",
        "                                                          num_train_steps, \n",
        "                                                          num_warmup_steps, \n",
        "                                                          use_tpu=False)\n",
        "\n",
        "            # Calculate evaluation metrics. \n",
        "            def metric_fn(label_ids, predicted_labels):\n",
        "                accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "                f1_score = tf.contrib.metrics.f1_score(label_ids, predicted_labels)\n",
        "                auc = tf.metrics.auc(label_ids, predicted_labels)\n",
        "                recall = tf.metrics.recall(label_ids, predicted_labels)\n",
        "                precision = tf.metrics.precision(label_ids, predicted_labels) \n",
        "                true_pos = tf.metrics.true_positives(label_ids, predicted_labels)\n",
        "                true_neg = tf.metrics.true_negatives(label_ids, predicted_labels)   \n",
        "                false_pos = tf.metrics.false_positives(label_ids, predicted_labels)  \n",
        "                false_neg = tf.metrics.false_negatives(label_ids, predicted_labels)\n",
        "\n",
        "                return {\n",
        "                    \"eval_accuracy\": accuracy,\n",
        "                    \"f1_score\": f1_score,\n",
        "                    \"auc\": auc,\n",
        "                    \"precision\": precision,\n",
        "                    \"recall\": recall,\n",
        "                    \"true_positives\": true_pos,\n",
        "                    \"true_negatives\": true_neg,\n",
        "                    \"false_positives\": false_pos,\n",
        "                    \"false_negatives\": false_neg\n",
        "                }\n",
        "\n",
        "            eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "            if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
        "            else:\n",
        "                return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metrics)\n",
        "        else:\n",
        "            (predicted_labels, log_probs) = create_model(is_predicting, \n",
        "                                                         input_ids, \n",
        "                                                         input_mask, \n",
        "                                                         segment_ids, \n",
        "                                                         label_ids, \n",
        "                                                         num_labels)\n",
        "\n",
        "            predictions = {'probabilities': log_probs, 'labels': predicted_labels}\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "    # Return the actual model function in the closure\n",
        "    return model_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H7ft96Zjb20J"
      },
      "outputs": [],
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3\n",
        "# Warmup is a period of time where the learning rate \n",
        "# is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 500\n",
        "SAVE_SUMMARY_STEPS = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "3ZAwxwmKb4QC"
      },
      "outputs": [],
      "source": [
        "# Compute # train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Y7a6E_Z1b5sk"
      },
      "outputs": [],
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\n",
        "OUTPUT_DIR = '../output'\n",
        "\n",
        "run_config = tf.estimator.RunConfig(model_dir=OUTPUT_DIR,\n",
        "                                    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "                                    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgBdv7SkAKAs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "7RoTS9Xtb7OY"
      },
      "outputs": [],
      "source": [
        "model_fn = model_fn_builder(num_labels=len(label_list), \n",
        "                            learning_rate=LEARNING_RATE,\n",
        "                            num_train_steps=num_train_steps,\n",
        "                            num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(model_fn=model_fn,\n",
        "                                   config=run_config,\n",
        "                                   params={\"batch_size\": BATCH_SIZE})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dbgNjFgJb9T4"
      },
      "outputs": [],
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(features=train_features,\n",
        "                                                      seq_length=MAX_SEQ_LENGTH,\n",
        "                                                      is_training=True,\n",
        "                                                      drop_remainder=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RZBgOrfob_UB"
      },
      "source": [
        "Fine-tuning BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ODmiwTNcBU5",
        "outputId": "71d4bb11-ff6b-4df9-db63-584886d364ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Started\n",
            "Training took  0:00:00.014658\n"
          ]
        }
      ],
      "source": [
        "print(f'Training Started')\n",
        "current_time = datetime.now()\n",
        "\n",
        "# train the model \n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "\n",
        "print(\"Training took \", datetime.now() - current_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NoWZVd7GSeu9"
      },
      "outputs": [],
      "source": [
        "# check the test result\n",
        "test_input_fn = run_classifier.input_fn_builder(features=test_features,\n",
        "                                                seq_length=MAX_SEQ_LENGTH,\n",
        "                                                is_training=False,\n",
        "                                                drop_remainder=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "841t7oB2Sjx4",
        "outputId": "3ea9440c-f5db-4266-ee4c-f15b49a564fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'auc': 0.8033624,\n",
              " 'eval_accuracy': 0.8041958,\n",
              " 'f1_score': 0.8138297,\n",
              " 'false_negatives': 63.0,\n",
              " 'false_positives': 77.0,\n",
              " 'loss': 0.83963794,\n",
              " 'precision': 0.7989556,\n",
              " 'recall': 0.8292683,\n",
              " 'true_negatives': 269.0,\n",
              " 'true_positives': 306.0,\n",
              " 'global_step': 532}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sWQL3FymSldf"
      },
      "outputs": [],
      "source": [
        "def predict(in_sentences):\n",
        "    CLASSES = [\"non-stress\", \"stress\"]\n",
        "\n",
        "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "\n",
        "    input_features = run_classifier.convert_examples_to_features(input_examples, \n",
        "                                                                 label_list, \n",
        "                                                                 MAX_SEQ_LENGTH, \n",
        "                                                                 tokenizer)\n",
        "    \n",
        "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, \n",
        "                                                       seq_length=MAX_SEQ_LENGTH, \n",
        "                                                       is_training=False, \n",
        "                                                       drop_remainder=False)\n",
        "\n",
        "    predictions = estimator.predict(predict_input_fn)\n",
        "    return [{\"input\": sentence, \"probabilities\": list(prediction['probabilities']), \"class\": CLASSES[prediction['labels']]}\n",
        "            for sentence, prediction in zip(in_sentences, predictions)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "gZgdWgqCSnoV"
      },
      "outputs": [],
      "source": [
        "pred_sentences = [\"Wow it's such a nice day today! I want to eat ice cream and have fun.\",\n",
        "\"Man. I'm so lazy today and just want to sleep all day. I don't feel like doing anything after that breakup.\",\n",
        "\"Do you like fruits? I like them so much! I'm very sad and depressed.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVo2vb_0SpV2",
        "outputId": "3f74d25f-7cbf-47cf-a214-deb0c9c825aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'input': \"Wow it's such a nice day today! I want to eat ice cream and have fun.\",\n",
              "  'probabilities': [-0.0026399782, -5.9383264],\n",
              "  'class': 'non-stress'},\n",
              " {'input': \"Man. I'm so lazy today and just want to sleep all day. I don't feel like doing anything after that breakup.\",\n",
              "  'probabilities': [-4.1206646, -0.016366992],\n",
              "  'class': 'stress'},\n",
              " {'input': \"Do you like fruits? I like them so much! I'm very sad and depressed.\",\n",
              "  'probabilities': [-6.314957, -0.0018106985],\n",
              "  'class': 'stress'}]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictions = predict(pred_sentences)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwwm6PuZSzvH"
      },
      "source": [
        "Save to File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "v_nYPFxOSxEA",
        "outputId": "d70ef85a-fc78-45b2-c9d3-8cc6b0e5a91e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "trained_checkpoint_prefix = '../output/model.ckpt-532'\n",
        "export_dir = '../bert_output/'\n",
        "\n",
        "graph = tf.Graph()\n",
        "with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    # Restore from checkpoint\n",
        "    loader = tf.compat.v1.train.import_meta_graph(trained_checkpoint_prefix + '.meta')\n",
        "    loader.restore(sess, trained_checkpoint_prefix)\n",
        "\n",
        "    # Export checkpoint to SavedModel\n",
        "    builder = tf.compat.v1.saved_model.builder.SavedModelBuilder(export_dir)\n",
        "    builder.add_meta_graph_and_variables(sess,\n",
        "                                         [tf.saved_model.TRAINING, tf.saved_model.SERVING],\n",
        "                                         strip_default_attrs=True)\n",
        "    builder.save()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdZc9yEzS6KD"
      },
      "source": [
        "Fine-tuned BERT For Serving"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "FP-TJ1LeS9m0"
      },
      "outputs": [],
      "source": [
        "def serving_input_fn():\n",
        "    label_ids = tf.placeholder(tf.int32, [None], name='label_ids')\n",
        "    input_ids = tf.placeholder(tf.int32, [None, MAX_SEQ_LENGTH], name='input_ids')\n",
        "    input_mask = tf.placeholder(tf.int32, [None, MAX_SEQ_LENGTH], name='input_mask')\n",
        "    segment_ids = tf.placeholder(tf.int32, [None, MAX_SEQ_LENGTH], name='segment_ids')\n",
        "    input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
        "        'label_ids': label_ids,\n",
        "        'input_ids': input_ids,\n",
        "        'input_mask': input_mask,\n",
        "        'segment_ids': segment_ids,\n",
        "    })()\n",
        "    return input_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(in_sentences):\n",
        "    CLASSES = [\"non-stress\", \"stress\"]\n",
        "\n",
        "    input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] # here, \"\" is just a dummy label\n",
        "\n",
        "    input_features = run_classifier.convert_examples_to_features(input_examples, \n",
        "                                                                 label_list, \n",
        "                                                                 MAX_SEQ_LENGTH, \n",
        "                                                                 tokenizer)\n",
        "    \n",
        "    predict_input_fn = run_classifier.input_fn_builder(features=input_features, \n",
        "                                                       seq_length=MAX_SEQ_LENGTH, \n",
        "                                                       is_training=False, \n",
        "                                                       drop_remainder=False)\n",
        "\n",
        "    predictions = estimator.predict(predict_input_fn)\n",
        "    return [{\"input\": sentence, \"probabilities\": list(prediction['probabilities']), \"class\": CLASSES[prediction['labels']]}\n",
        "            for sentence, prediction in zip(in_sentences, predictions)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1jpy651S-Uz",
        "outputId": "444e6d39-9404-4aef-9118-efcd69ef97d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "b'../output\\\\1641956961'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "estimator._export_to_tpu = False\n",
        "estimator.export_savedmodel(OUTPUT_DIR, serving_input_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
            "\n",
            "signature_def['serving_default']:\n",
            "  The given SavedModel SignatureDef contains the following input(s):\n",
            "    inputs['input_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 310)\n",
            "        name: input_ids_1:0\n",
            "    inputs['input_mask'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 310)\n",
            "        name: input_mask_1:0\n",
            "    inputs['label_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1)\n",
            "        name: label_ids_1:0\n",
            "    inputs['segment_ids'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1, 310)\n",
            "        name: segment_ids_1:0\n",
            "  The given SavedModel SignatureDef contains the following output(s):\n",
            "    outputs['labels'] tensor_info:\n",
            "        dtype: DT_INT32\n",
            "        shape: (-1)\n",
            "        name: loss/ArgMax:0\n",
            "    outputs['probabilities'] tensor_info:\n",
            "        dtype: DT_FLOAT\n",
            "        shape: (-1, 2)\n",
            "        name: loss/LogSoftmax:0\n",
            "  Method name is: tensorflow/serving/predict\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-01-12 12:10:23.265027: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'cudart64_100.dll'; dlerror: cudart64_100.dll not found\n",
            "2022-01-12 12:10:23.265290: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
          ]
        }
      ],
      "source": [
        "# !saved_model_cli show --dir ../output/1641956961/ --all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'tensorflow_model_server' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "#!tensorflow_model_server --port=8500 --rest_api_port=8501 --model_name=bert_model --model_base_path=/output"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "QuickCheckBERT.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "8263150b0dc19897827196505efb3f27a1f974226b57dadb7cde605001e6d83c"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('quick_check': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
